{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-28 07:48:52.587395: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-28 07:48:52.687616: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-28 07:48:53.260203: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/bagnol/miniconda3/envs/anagoup/lib/\n",
      "2023-04-28 07:48:53.260261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/bagnol/miniconda3/envs/anagoup/lib/\n",
      "2023-04-28 07:48:53.260267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sentence=list()\n",
    "Y_sentence=list()\n",
    "count=0\n",
    "base_path=\"../dataset\"\n",
    "X_train=list()\n",
    "Y_train=list()\n",
    "X_val=list()\n",
    "Y_val=list()\n",
    "X_test=list()\n",
    "Y_test=list()\n",
    "with open(base_path+\"/S1-test.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        if(line!='\\n'):\n",
    "            X_sentence.append(line.split(\" \")[0])\n",
    "            Y_sentence.append(line.split(\" \")[1][:-1])\n",
    "        else:\n",
    "            count+=1\n",
    "            if(count==2):\n",
    "                X_test.append(X_sentence)      \n",
    "                Y_test.append(Y_sentence)        \n",
    "                X_sentence=list()\n",
    "                Y_sentence=list()\n",
    "                count=0\n",
    "with open(base_path+\"/S2-train.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        if(line!='\\n'):\n",
    "            X_sentence.append(line.split(\" \")[0])\n",
    "            Y_sentence.append(line.split(\" \")[1][:-1])\n",
    "        else:\n",
    "            count+=1\n",
    "            if(count==2):\n",
    "                X_train.append(X_sentence)      \n",
    "                Y_train.append(Y_sentence)        \n",
    "                X_sentence=list()\n",
    "                Y_sentence=list()\n",
    "                count=0\n",
    "with open(base_path+\"/S3-val.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        if(line!='\\n'):\n",
    "            X_sentence.append(line.split(\" \")[0])\n",
    "            Y_sentence.append(line.split(\" \")[1][:-1])\n",
    "        else:\n",
    "            count+=1\n",
    "            if(count==2):\n",
    "                X_val.append(X_sentence)      \n",
    "                Y_val.append(Y_sentence)        \n",
    "                X_sentence=list()\n",
    "                Y_sentence=list()\n",
    "                count=0\n",
    "# sentences it is a list of sentences. Every sentence is a list of tuple\n",
    "tokenized_sentences=X_train+X_test+X_val\n",
    "tokenized_labels=Y_train+Y_test+Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occorrenza di BIOP\n",
      "\ttrain: 91\n",
      "\tval: 11\n",
      "\ttest: 134\n",
      "occorrenza di APPL\n",
      "\ttrain: 1357\n",
      "\tval: 331\n",
      "\ttest: 532\n",
      "occorrenza di CHAR\n",
      "\ttrain: 1738\n",
      "\tval: 243\n",
      "\ttest: 256\n",
      "occorrenza di CONPRI\n",
      "\ttrain: 15435\n",
      "\tval: 3239\n",
      "\ttest: 2604\n",
      "occorrenza di ENAT\n",
      "\ttrain: 860\n",
      "\tval: 197\n",
      "\ttest: 181\n",
      "occorrenza di FEAT\n",
      "\ttrain: 1357\n",
      "\tval: 487\n",
      "\ttest: 782\n",
      "occorrenza di MACEQ\n",
      "\ttrain: 1761\n",
      "\tval: 471\n",
      "\ttest: 326\n",
      "occorrenza di MANP\n",
      "\ttrain: 7417\n",
      "\tval: 1919\n",
      "\ttest: 1314\n",
      "occorrenza di MANS\n",
      "\ttrain: 38\n",
      "\tval: 50\n",
      "\ttest: 14\n",
      "occorrenza di MATE\n",
      "\ttrain: 9055\n",
      "\tval: 1795\n",
      "\ttest: 2181\n",
      "occorrenza di PARA\n",
      "\ttrain: 2576\n",
      "\tval: 481\n",
      "\ttest: 422\n",
      "occorrenza di PRO\n",
      "\ttrain: 3736\n",
      "\tval: 504\n",
      "\ttest: 882\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for el in [\"BIOP\",\"APPL\",\"CHAR\",\"CONPRI\",\"ENAT\",\"FEAT\",\"MACEQ\",\"MANP\",\"MANS\",\"MATE\",\"PARA\",\"PRO\"]:\n",
    "    counter=0\n",
    "    print(\"occorrenza di \"+el)\n",
    "    for y in Y_train:\n",
    "        for lab in y:\n",
    "            if lab!=\"0\" and lab[2:]==el and (lab[0]==\"B\" or lab[0]==\"S\"):\n",
    "                counter+=1\n",
    "    print(\"\\ttrain: \"+str(counter))        \n",
    "    counter=0\n",
    "    for y in Y_val:\n",
    "        for lab in y:\n",
    "            if lab!=\"0\" and lab[2:]==el and (lab[0]==\"B\" or lab[0]==\"S\"):\n",
    "                counter+=1\n",
    "    print(\"\\tval: \"+str(counter))   \n",
    "    counter=0\n",
    "    for y in Y_test:\n",
    "        for lab in y:\n",
    "            if lab!=\"0\" and lab[2:]==el and (lab[0]==\"B\" or lab[0]==\"S\"):\n",
    "                counter+=1\n",
    "    print(\"\\ttest: \"+str(counter))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model_2=FastText(sentences=X_train, vector_size=100, window=10, min_count=5, sg=1, negative=10, alpha=0.01, sample=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.train(X_train, total_examples=len(tokenized_sentences), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 10:04:28.369664: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 10:04:28.489483: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-22 10:04:29.069683: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/bagnol/miniconda3/envs/anagoup/lib/\n",
      "2023-03-22 10:04:29.069750: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/bagnol/miniconda3/envs/anagoup/lib/\n",
      "2023-03-22 10:04:29.069756: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-03-22 10:04:30.135178: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 10:04:30.752920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22124 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 0000:3b:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bagnol/miniconda3/envs/anagoup/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 49) dtype=float32 (created by layer 'crf')>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelli.wrapper import Sequence\n",
    "import tensorflow as tf\n",
    "\n",
    "lstm=Sequence(embeddings=model_2.wv, initial_vocab=model_2.wv.key_to_index)\n",
    "lstm.fit_vocab(X_train,Y_train)\n",
    "lstm.model.call((tf.keras.Input(shape=[None]),tf.keras.Input(shape=[None,None])),training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 10:09:31.914124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-22 10:09:32.626981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 10:09:43.731970: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_40/output/_23'\n",
      "2023-03-22 10:09:44.692625: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f6d0f1abbc0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-22 10:09:44.692658: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA A30, Compute Capability 8.0\n",
      "2023-03-22 10:09:44.697056: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-22 10:09:44.762414: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-03-22 10:09:44.806557: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - ETA: 0s - loss: 9.9156 - f1: 74.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bagnol/miniconda3/envs/anagoup/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.80      0.72      0.76       331\n",
      "        BIOP       0.00      0.00      0.00        12\n",
      "        CHAR       0.72      0.64      0.68       243\n",
      "      CONPRI       0.75      0.75      0.75      3239\n",
      "        ENAT       0.59      0.31      0.41       197\n",
      "        FEAT       0.70      0.47      0.56       487\n",
      "       MACEQ       0.80      0.54      0.65       471\n",
      "        MANP       0.75      0.83      0.79      1919\n",
      "        MANS       0.00      0.00      0.00        51\n",
      "        MATE       0.86      0.85      0.86      1795\n",
      "        PARA       0.64      0.71      0.67       481\n",
      "         PRO       0.62      0.78      0.69       504\n",
      "\n",
      "   micro avg       0.75      0.74      0.75      9730\n",
      "   macro avg       0.60      0.55      0.57      9730\n",
      "weighted avg       0.75      0.74      0.74      9730\n",
      "\n",
      "74/74 [==============================] - 57s 597ms/step - loss: 9.9156 - val_loss: 9.2500 - f1: 0.7493\n",
      "Epoch 2/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8918 - f1: 76.39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.79      0.73      0.76       331\n",
      "        BIOP       0.00      0.00      0.00        12\n",
      "        CHAR       0.71      0.67      0.69       243\n",
      "      CONPRI       0.78      0.76      0.77      3239\n",
      "        ENAT       0.57      0.34      0.43       197\n",
      "        FEAT       0.68      0.55      0.61       487\n",
      "       MACEQ       0.78      0.61      0.69       471\n",
      "        MANP       0.74      0.84      0.78      1919\n",
      "        MANS       0.00      0.00      0.00        51\n",
      "        MATE       0.85      0.86      0.85      1795\n",
      "        PARA       0.70      0.72      0.71       481\n",
      "         PRO       0.70      0.79      0.74       504\n",
      "\n",
      "   micro avg       0.77      0.76      0.76      9730\n",
      "   macro avg       0.61      0.57      0.59      9730\n",
      "weighted avg       0.76      0.76      0.76      9730\n",
      "\n",
      "74/74 [==============================] - 17s 226ms/step - loss: 9.8918 - val_loss: 9.2341 - f1: 0.7639\n",
      "Epoch 3/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8728 - f1: 77.91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.83      0.73      0.78       331\n",
      "        BIOP       1.00      0.08      0.15        12\n",
      "        CHAR       0.65      0.70      0.67       243\n",
      "      CONPRI       0.81      0.77      0.79      3239\n",
      "        ENAT       0.61      0.34      0.44       197\n",
      "        FEAT       0.70      0.60      0.64       487\n",
      "       MACEQ       0.76      0.63      0.69       471\n",
      "        MANP       0.77      0.84      0.80      1919\n",
      "        MANS       0.00      0.00      0.00        51\n",
      "        MATE       0.86      0.87      0.87      1795\n",
      "        PARA       0.72      0.74      0.73       481\n",
      "         PRO       0.74      0.80      0.77       504\n",
      "\n",
      "   micro avg       0.79      0.77      0.78      9730\n",
      "   macro avg       0.70      0.59      0.61      9730\n",
      "weighted avg       0.78      0.77      0.77      9730\n",
      "\n",
      "74/74 [==============================] - 17s 227ms/step - loss: 9.8728 - val_loss: 9.2264 - f1: 0.7791\n",
      "Epoch 4/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8572 - f1: 78.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.83      0.75      0.79       331\n",
      "        BIOP       0.62      0.42      0.50        12\n",
      "        CHAR       0.67      0.69      0.68       243\n",
      "      CONPRI       0.81      0.77      0.79      3239\n",
      "        ENAT       0.58      0.36      0.44       197\n",
      "        FEAT       0.69      0.61      0.65       487\n",
      "       MACEQ       0.78      0.64      0.70       471\n",
      "        MANP       0.77      0.83      0.80      1919\n",
      "        MANS       0.00      0.00      0.00        51\n",
      "        MATE       0.87      0.87      0.87      1795\n",
      "        PARA       0.77      0.74      0.75       481\n",
      "         PRO       0.76      0.83      0.79       504\n",
      "\n",
      "   micro avg       0.80      0.77      0.78      9730\n",
      "   macro avg       0.68      0.63      0.65      9730\n",
      "weighted avg       0.79      0.77      0.78      9730\n",
      "\n",
      "74/74 [==============================] - 17s 231ms/step - loss: 9.8572 - val_loss: 9.2246 - f1: 0.7845\n",
      "Epoch 5/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8435 - f1: 78.91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.85      0.76      0.80       331\n",
      "        BIOP       0.50      0.58      0.54        12\n",
      "        CHAR       0.67      0.70      0.69       243\n",
      "      CONPRI       0.81      0.78      0.80      3239\n",
      "        ENAT       0.65      0.37      0.47       197\n",
      "        FEAT       0.71      0.62      0.66       487\n",
      "       MACEQ       0.81      0.63      0.71       471\n",
      "        MANP       0.76      0.84      0.80      1919\n",
      "        MANS       0.00      0.00      0.00        51\n",
      "        MATE       0.88      0.87      0.87      1795\n",
      "        PARA       0.79      0.75      0.77       481\n",
      "         PRO       0.78      0.81      0.80       504\n",
      "\n",
      "   micro avg       0.80      0.78      0.79      9730\n",
      "   macro avg       0.68      0.64      0.66      9730\n",
      "weighted avg       0.79      0.78      0.78      9730\n",
      "\n",
      "74/74 [==============================] - 18s 240ms/step - loss: 9.8435 - val_loss: 9.2163 - f1: 0.7891\n",
      "Epoch 6/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8320 - f1: 79.17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.89      0.74      0.81       331\n",
      "        BIOP       0.35      0.58      0.44        12\n",
      "        CHAR       0.69      0.70      0.70       243\n",
      "      CONPRI       0.80      0.79      0.80      3239\n",
      "        ENAT       0.69      0.43      0.53       197\n",
      "        FEAT       0.70      0.63      0.66       487\n",
      "       MACEQ       0.81      0.64      0.71       471\n",
      "        MANP       0.77      0.85      0.81      1919\n",
      "        MANS       0.50      0.02      0.04        51\n",
      "        MATE       0.87      0.86      0.86      1795\n",
      "        PARA       0.78      0.77      0.77       481\n",
      "         PRO       0.78      0.82      0.80       504\n",
      "\n",
      "   micro avg       0.80      0.79      0.79      9730\n",
      "   macro avg       0.72      0.65      0.66      9730\n",
      "weighted avg       0.80      0.79      0.79      9730\n",
      "\n",
      "74/74 [==============================] - 18s 237ms/step - loss: 9.8320 - val_loss: 9.2075 - f1: 0.7917\n",
      "Epoch 7/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8232 - f1: 79.40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.86      0.78      0.82       331\n",
      "        BIOP       0.35      0.67      0.46        12\n",
      "        CHAR       0.69      0.71      0.70       243\n",
      "      CONPRI       0.81      0.79      0.80      3239\n",
      "        ENAT       0.65      0.40      0.50       197\n",
      "        FEAT       0.69      0.66      0.67       487\n",
      "       MACEQ       0.77      0.65      0.71       471\n",
      "        MANP       0.77      0.84      0.81      1919\n",
      "        MANS       0.50      0.02      0.04        51\n",
      "        MATE       0.86      0.87      0.87      1795\n",
      "        PARA       0.80      0.76      0.78       481\n",
      "         PRO       0.82      0.82      0.82       504\n",
      "\n",
      "   micro avg       0.80      0.79      0.79      9730\n",
      "   macro avg       0.72      0.66      0.66      9730\n",
      "weighted avg       0.80      0.79      0.79      9730\n",
      "\n",
      "74/74 [==============================] - 17s 230ms/step - loss: 9.8232 - val_loss: 9.2093 - f1: 0.7940\n",
      "Epoch 8/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8140 - f1: 79.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.86      0.79      0.82       331\n",
      "        BIOP       0.31      0.67      0.42        12\n",
      "        CHAR       0.68      0.73      0.70       243\n",
      "      CONPRI       0.81      0.77      0.79      3239\n",
      "        ENAT       0.69      0.43      0.53       197\n",
      "        FEAT       0.72      0.63      0.67       487\n",
      "       MACEQ       0.80      0.67      0.73       471\n",
      "        MANP       0.78      0.84      0.81      1919\n",
      "        MANS       0.67      0.04      0.07        51\n",
      "        MATE       0.87      0.88      0.87      1795\n",
      "        PARA       0.77      0.78      0.77       481\n",
      "         PRO       0.81      0.84      0.82       504\n",
      "\n",
      "   micro avg       0.80      0.79      0.79      9730\n",
      "   macro avg       0.73      0.67      0.67      9730\n",
      "weighted avg       0.80      0.79      0.79      9730\n",
      "\n",
      "74/74 [==============================] - 18s 242ms/step - loss: 9.8140 - val_loss: 9.2025 - f1: 0.7941\n",
      "Epoch 9/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.8063 - f1: 79.10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.84      0.79      0.81       331\n",
      "        BIOP       0.29      0.67      0.40        12\n",
      "        CHAR       0.53      0.72      0.61       243\n",
      "      CONPRI       0.80      0.78      0.79      3239\n",
      "        ENAT       0.74      0.46      0.57       197\n",
      "        FEAT       0.68      0.67      0.68       487\n",
      "       MACEQ       0.78      0.70      0.74       471\n",
      "        MANP       0.78      0.84      0.81      1919\n",
      "        MANS       0.75      0.06      0.11        51\n",
      "        MATE       0.87      0.87      0.87      1795\n",
      "        PARA       0.72      0.79      0.75       481\n",
      "         PRO       0.80      0.84      0.82       504\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      9730\n",
      "   macro avg       0.72      0.68      0.66      9730\n",
      "weighted avg       0.79      0.79      0.79      9730\n",
      "\n",
      "74/74 [==============================] - 18s 241ms/step - loss: 9.8063 - val_loss: 9.2020 - f1: 0.7910\n",
      "Epoch 10/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7997 - f1: 79.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.87      0.78      0.82       331\n",
      "        BIOP       0.31      0.67      0.42        12\n",
      "        CHAR       0.67      0.72      0.69       243\n",
      "      CONPRI       0.83      0.78      0.80      3239\n",
      "        ENAT       0.69      0.45      0.55       197\n",
      "        FEAT       0.69      0.66      0.68       487\n",
      "       MACEQ       0.78      0.71      0.74       471\n",
      "        MANP       0.79      0.83      0.81      1919\n",
      "        MANS       0.86      0.12      0.21        51\n",
      "        MATE       0.87      0.87      0.87      1795\n",
      "        PARA       0.77      0.78      0.77       481\n",
      "         PRO       0.81      0.84      0.83       504\n",
      "\n",
      "   micro avg       0.81      0.79      0.80      9730\n",
      "   macro avg       0.74      0.68      0.68      9730\n",
      "weighted avg       0.81      0.79      0.80      9730\n",
      "\n",
      "74/74 [==============================] - 18s 238ms/step - loss: 9.7997 - val_loss: 9.2038 - f1: 0.7989\n",
      "Epoch 11/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7935 - f1: 79.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.86      0.82      0.84       331\n",
      "        BIOP       0.28      0.67      0.39        12\n",
      "        CHAR       0.54      0.73      0.62       243\n",
      "      CONPRI       0.82      0.78      0.80      3239\n",
      "        ENAT       0.73      0.49      0.59       197\n",
      "        FEAT       0.69      0.65      0.67       487\n",
      "       MACEQ       0.79      0.69      0.74       471\n",
      "        MANP       0.79      0.85      0.82      1919\n",
      "        MANS       0.86      0.12      0.21        51\n",
      "        MATE       0.87      0.87      0.87      1795\n",
      "        PARA       0.77      0.77      0.77       481\n",
      "         PRO       0.80      0.84      0.82       504\n",
      "\n",
      "   micro avg       0.80      0.79      0.80      9730\n",
      "   macro avg       0.73      0.69      0.68      9730\n",
      "weighted avg       0.80      0.79      0.79      9730\n",
      "\n",
      "74/74 [==============================] - 19s 251ms/step - loss: 9.7935 - val_loss: 9.2029 - f1: 0.7958\n",
      "Epoch 12/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7874 - f1: 79.27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.85      0.81      0.83       331\n",
      "        BIOP       0.31      0.67      0.42        12\n",
      "        CHAR       0.64      0.75      0.69       243\n",
      "      CONPRI       0.79      0.77      0.78      3239\n",
      "        ENAT       0.72      0.48      0.57       197\n",
      "        FEAT       0.70      0.66      0.68       487\n",
      "       MACEQ       0.76      0.72      0.74       471\n",
      "        MANP       0.80      0.83      0.81      1919\n",
      "        MANS       0.78      0.14      0.23        51\n",
      "        MATE       0.87      0.86      0.87      1795\n",
      "        PARA       0.78      0.78      0.78       481\n",
      "         PRO       0.82      0.84      0.83       504\n",
      "\n",
      "   micro avg       0.80      0.79      0.79      9730\n",
      "   macro avg       0.73      0.69      0.69      9730\n",
      "weighted avg       0.80      0.79      0.79      9730\n",
      "\n",
      "74/74 [==============================] - 18s 238ms/step - loss: 9.7874 - val_loss: 9.2008 - f1: 0.7927\n",
      "Epoch 13/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7822 - f1: 79.19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.86      0.82      0.84       331\n",
      "        BIOP       0.35      0.67      0.46        12\n",
      "        CHAR       0.56      0.76      0.64       243\n",
      "      CONPRI       0.79      0.77      0.78      3239\n",
      "        ENAT       0.72      0.50      0.59       197\n",
      "        FEAT       0.68      0.67      0.67       487\n",
      "       MACEQ       0.77      0.71      0.74       471\n",
      "        MANP       0.81      0.85      0.83      1919\n",
      "        MANS       0.83      0.20      0.32        51\n",
      "        MATE       0.86      0.87      0.87      1795\n",
      "        PARA       0.77      0.77      0.77       481\n",
      "         PRO       0.81      0.84      0.83       504\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      9730\n",
      "   macro avg       0.73      0.70      0.69      9730\n",
      "weighted avg       0.79      0.79      0.79      9730\n",
      "\n",
      "74/74 [==============================] - 17s 235ms/step - loss: 9.7822 - val_loss: 9.2026 - f1: 0.7919\n",
      "Epoch 14/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7776 - f1: 79.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.86      0.81      0.84       331\n",
      "        BIOP       0.29      0.67      0.40        12\n",
      "        CHAR       0.68      0.73      0.71       243\n",
      "      CONPRI       0.80      0.78      0.79      3239\n",
      "        ENAT       0.73      0.49      0.58       197\n",
      "        FEAT       0.69      0.66      0.68       487\n",
      "       MACEQ       0.77      0.70      0.74       471\n",
      "        MANP       0.80      0.84      0.82      1919\n",
      "        MANS       0.78      0.14      0.23        51\n",
      "        MATE       0.88      0.87      0.87      1795\n",
      "        PARA       0.76      0.79      0.78       481\n",
      "         PRO       0.82      0.86      0.84       504\n",
      "\n",
      "   micro avg       0.81      0.79      0.80      9730\n",
      "   macro avg       0.74      0.69      0.69      9730\n",
      "weighted avg       0.81      0.79      0.80      9730\n",
      "\n",
      "74/74 [==============================] - 18s 243ms/step - loss: 9.7776 - val_loss: 9.2042 - f1: 0.7987\n",
      "Epoch 15/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7732 - f1: 80.06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.85      0.81      0.83       331\n",
      "        BIOP       0.32      0.67      0.43        12\n",
      "        CHAR       0.67      0.76      0.71       243\n",
      "      CONPRI       0.82      0.78      0.80      3239\n",
      "        ENAT       0.68      0.51      0.58       197\n",
      "        FEAT       0.70      0.65      0.67       487\n",
      "       MACEQ       0.78      0.72      0.75       471\n",
      "        MANP       0.79      0.84      0.82      1919\n",
      "        MANS       0.83      0.20      0.32        51\n",
      "        MATE       0.87      0.87      0.87      1795\n",
      "        PARA       0.75      0.78      0.77       481\n",
      "         PRO       0.85      0.83      0.84       504\n",
      "\n",
      "   micro avg       0.81      0.79      0.80      9730\n",
      "   macro avg       0.74      0.70      0.70      9730\n",
      "weighted avg       0.81      0.79      0.80      9730\n",
      "\n",
      "74/74 [==============================] - 18s 238ms/step - loss: 9.7732 - val_loss: 9.2068 - f1: 0.8006\n",
      "Epoch 16/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7696 - f1: 79.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.85      0.81      0.83       331\n",
      "        BIOP       0.32      0.67      0.43        12\n",
      "        CHAR       0.60      0.74      0.67       243\n",
      "      CONPRI       0.79      0.78      0.79      3239\n",
      "        ENAT       0.73      0.48      0.58       197\n",
      "        FEAT       0.68      0.67      0.67       487\n",
      "       MACEQ       0.78      0.71      0.74       471\n",
      "        MANP       0.79      0.84      0.82      1919\n",
      "        MANS       0.86      0.24      0.37        51\n",
      "        MATE       0.87      0.87      0.87      1795\n",
      "        PARA       0.79      0.75      0.77       481\n",
      "         PRO       0.84      0.84      0.84       504\n",
      "\n",
      "   micro avg       0.80      0.79      0.79      9730\n",
      "   macro avg       0.74      0.70      0.70      9730\n",
      "weighted avg       0.80      0.79      0.79      9730\n",
      "\n",
      "74/74 [==============================] - 18s 240ms/step - loss: 9.7696 - val_loss: 9.2125 - f1: 0.7945\n",
      "Epoch 17/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7669 - f1: 79.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.85      0.80      0.83       331\n",
      "        BIOP       0.38      0.67      0.48        12\n",
      "        CHAR       0.66      0.76      0.70       243\n",
      "      CONPRI       0.81      0.77      0.79      3239\n",
      "        ENAT       0.72      0.50      0.59       197\n",
      "        FEAT       0.72      0.63      0.67       487\n",
      "       MACEQ       0.77      0.74      0.75       471\n",
      "        MANP       0.79      0.85      0.82      1919\n",
      "        MANS       0.81      0.25      0.39        51\n",
      "        MATE       0.85      0.86      0.86      1795\n",
      "        PARA       0.77      0.78      0.78       481\n",
      "         PRO       0.84      0.86      0.85       504\n",
      "\n",
      "   micro avg       0.80      0.79      0.80      9730\n",
      "   macro avg       0.75      0.71      0.71      9730\n",
      "weighted avg       0.80      0.79      0.79      9730\n",
      "\n",
      "74/74 [==============================] - 18s 247ms/step - loss: 9.7669 - val_loss: 9.2117 - f1: 0.7966\n",
      "Epoch 18/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7636 - f1: 79.63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.87      0.81      0.84       331\n",
      "        BIOP       0.35      0.67      0.46        12\n",
      "        CHAR       0.69      0.73      0.71       243\n",
      "      CONPRI       0.79      0.78      0.78      3239\n",
      "        ENAT       0.69      0.51      0.59       197\n",
      "        FEAT       0.70      0.65      0.67       487\n",
      "       MACEQ       0.80      0.73      0.76       471\n",
      "        MANP       0.80      0.84      0.82      1919\n",
      "        MANS       0.83      0.29      0.43        51\n",
      "        MATE       0.87      0.86      0.86      1795\n",
      "        PARA       0.74      0.79      0.76       481\n",
      "         PRO       0.83      0.85      0.84       504\n",
      "\n",
      "   micro avg       0.80      0.79      0.80      9730\n",
      "   macro avg       0.75      0.71      0.71      9730\n",
      "weighted avg       0.80      0.79      0.80      9730\n",
      "\n",
      "74/74 [==============================] - 18s 243ms/step - loss: 9.7636 - val_loss: 9.2134 - f1: 0.7963\n",
      "Epoch 19/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7592 - f1: 79.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.85      0.80      0.83       331\n",
      "        BIOP       0.38      0.67      0.48        12\n",
      "        CHAR       0.60      0.77      0.68       243\n",
      "      CONPRI       0.78      0.77      0.78      3239\n",
      "        ENAT       0.71      0.50      0.59       197\n",
      "        FEAT       0.70      0.64      0.67       487\n",
      "       MACEQ       0.78      0.75      0.76       471\n",
      "        MANP       0.80      0.84      0.82      1919\n",
      "        MANS       0.81      0.25      0.39        51\n",
      "        MATE       0.85      0.85      0.85      1795\n",
      "        PARA       0.75      0.78      0.76       481\n",
      "         PRO       0.82      0.87      0.84       504\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      9730\n",
      "   macro avg       0.74      0.71      0.70      9730\n",
      "weighted avg       0.79      0.79      0.79      9730\n",
      "\n",
      "74/74 [==============================] - 18s 241ms/step - loss: 9.7592 - val_loss: 9.2190 - f1: 0.7902\n",
      "Epoch 20/20\n",
      "74/74 [==============================] - ETA: 0s - loss: 9.7563 - f1: 80.14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        APPL       0.83      0.81      0.82       331\n",
      "        BIOP       0.32      0.67      0.43        12\n",
      "        CHAR       0.70      0.74      0.72       243\n",
      "      CONPRI       0.82      0.78      0.80      3239\n",
      "        ENAT       0.69      0.50      0.58       197\n",
      "        FEAT       0.70      0.63      0.67       487\n",
      "       MACEQ       0.80      0.73      0.76       471\n",
      "        MANP       0.79      0.83      0.81      1919\n",
      "        MANS       0.81      0.25      0.39        51\n",
      "        MATE       0.86      0.87      0.87      1795\n",
      "        PARA       0.79      0.78      0.79       481\n",
      "         PRO       0.86      0.85      0.85       504\n",
      "\n",
      "   micro avg       0.81      0.79      0.80      9730\n",
      "   macro avg       0.75      0.70      0.71      9730\n",
      "weighted avg       0.81      0.79      0.80      9730\n",
      "\n",
      "74/74 [==============================] - 18s 243ms/step - loss: 9.7563 - val_loss: 9.2285 - f1: 0.8014\n"
     ]
    }
   ],
   "source": [
    "from modelli.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(lstm.model, preprocessor=lstm.p)\n",
    "trainer.train(X_train, Y_train, X_val, Y_val, epochs=20, batch_size=128, verbose=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.save(model_file=\"model\", preprocessor_file=\"preprocessor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-22 10:08:43.617143: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-22 10:08:44.229328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22124 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 0000:3b:00.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bagnol/miniconda3/envs/anagoup/lib/python3.10/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, None, 49) dtype=float32 (created by layer 'crf')>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modelli.wrapper import Sequence\n",
    "import tensorflow as tf\n",
    "\n",
    "lstm=Sequence(embeddings=None, initial_vocab=None)\n",
    "lstm.fit_vocab(X_train,Y_train)\n",
    "lstm.load(model_file=\"model\", preprocessor_file=\"preprocessor\")\n",
    "lstm.model.call((tf.keras.Input(shape=[None]),tf.keras.Input(shape=[None,None])),training=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anagoup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7613704cca6be61a35926d07e845db46a5adaf3e0bd32c31c32b93fe29930a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
