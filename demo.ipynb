{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first install python 3.6\n",
    "!sudo apt-get update -y\n",
    "!sudo apt-get install python3.6\n",
    "# change alternatives\n",
    "!sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 1\n",
    "# select python version\n",
    "!sudo update-alternatives --config python3\n",
    "# check python version\n",
    "!python --version\n",
    "# install pip for new python \n",
    "!sudo apt-get install python3.6-distutils\n",
    "!wget https://bootstrap.pypa.io/get-pip.py\n",
    "!python get-pip.py\n",
    "# upgrade pip\n",
    "!sudo apt install python3-pip\n",
    "!python -m pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sentence=list()\n",
    "Y_sentence=list()\n",
    "count=0\n",
    "base_path=\"dataset\"\n",
    "X_train=list()\n",
    "Y_train=list()\n",
    "X_val=list()\n",
    "Y_val=list()\n",
    "X_test=list()\n",
    "Y_test=list()\n",
    "with open(base_path+\"/S1-test.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        if(line!='\\n'):\n",
    "            X_sentence.append(line.split(\" \")[0])\n",
    "            Y_sentence.append(line.split(\" \")[1][:-1])\n",
    "        else:\n",
    "            count+=1\n",
    "            if(count==2):\n",
    "                X_test.append(X_sentence)      \n",
    "                Y_test.append(Y_sentence)        \n",
    "                X_sentence=list()\n",
    "                Y_sentence=list()\n",
    "                count=0\n",
    "with open(base_path+\"/S2-train.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        if(line!='\\n'):\n",
    "            X_sentence.append(line.split(\" \")[0])\n",
    "            Y_sentence.append(line.split(\" \")[1][:-1])\n",
    "        else:\n",
    "            count+=1\n",
    "            if(count==2):\n",
    "                X_train.append(X_sentence)      \n",
    "                Y_train.append(Y_sentence)        \n",
    "                X_sentence=list()\n",
    "                Y_sentence=list()\n",
    "                count=0\n",
    "with open(base_path+\"/S3-val.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        if(line!='\\n'):\n",
    "            X_sentence.append(line.split(\" \")[0])\n",
    "            Y_sentence.append(line.split(\" \")[1][:-1])\n",
    "        else:\n",
    "            count+=1\n",
    "            if(count==2):\n",
    "                X_val.append(X_sentence)      \n",
    "                Y_val.append(Y_sentence)        \n",
    "                X_sentence=list()\n",
    "                Y_sentence=list()\n",
    "                count=0\n",
    "# sentences it is a list of sentences. Every sentence is a list of tuple\n",
    "tokenized_sentences=X_train+X_test+X_val\n",
    "tokenized_labels=Y_train+Y_test+Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model_2=FastText(sentences=tokenized_sentences, vector_size=100, window=10, min_count=5, sg=1, negative=10, alpha=0.01, sample=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3049188, 6991040)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.train(tokenized_sentences, total_examples=len(tokenized_sentences), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CMT', 0.9488525986671448),\n",
       " ('GTAW', 0.9404873251914978),\n",
       " ('Gas', 0.933182418346405),\n",
       " ('GMAW', 0.9262470602989197),\n",
       " ('Plasma', 0.922127366065979),\n",
       " ('wire-arc', 0.9121090769767761),\n",
       " ('Tungsten', 0.9078242778778076),\n",
       " ('Arc', 0.8962817192077637),\n",
       " ('tungsten', 0.8776745796203613),\n",
       " ('7075', 0.873650312423706)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.wv.most_similar(\"TIG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from modelli import wrapper, utils\n",
    "importlib.reload(wrapper)\n",
    "from modelli.wrapper import Sequence\n",
    "\n",
    "\n",
    "lstm=Sequence(embeddings=model_2.wv, initial_vocab=model_2.wv.key_to_index)\n",
    "lstm.fit_vocab(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4825"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lstm.p._word_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelli.wrapper import Sequence\n",
    "import pickle\n",
    "\n",
    "lstm=Sequence.load(\"param\",\"weights.h5\",\"preprocessor\")\n",
    "lstm.model.compile( optimizer=lstm.optimizer)\n",
    "with open('optimizer.pkl', 'rb') as f:\n",
    "    weight_values = pickle.load(f)\n",
    "lstm.model.optimizer.set_weights(weight_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "indices[18,18] = 4824 is not in [0, 4824)\n\t [[{{node word_embedding_3/embedding_lookup}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodelli\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtrainer\u001b[39;00m \u001b[39mimport\u001b[39;00m Trainer\n\u001b[1;32m      8\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(lstm\u001b[39m.\u001b[39mmodel, preprocessor\u001b[39m=\u001b[39mlstm\u001b[39m.\u001b[39mp)\n\u001b[0;32m----> 9\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(X_train, Y_train, X_val, Y_val, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/projects/NER_Manufacturing-FabNER/FabNER-implementation/modelli/trainer.py:50\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, x_train, y_train, x_valid, y_valid, epochs, batch_size, verbose, callbacks, shuffle)\u001b[0m\n\u001b[1;32m     47\u001b[0m     f1 \u001b[39m=\u001b[39m F1score(valid_seq, preprocessor\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_preprocessor)\n\u001b[1;32m     48\u001b[0m     callbacks \u001b[39m=\u001b[39m [f1] \u001b[39m+\u001b[39m callbacks \u001b[39mif\u001b[39;00m callbacks \u001b[39melse\u001b[39;00m [f1]\n\u001b[0;32m---> 50\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mtrain_seq, validation_data\u001b[39m=\u001b[39;49mvalid_seq,\n\u001b[1;32m     51\u001b[0m                           epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     52\u001b[0m                           callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m     53\u001b[0m                           verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m     54\u001b[0m                           shuffle\u001b[39m=\u001b[39;49mshuffle)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/anagoup/lib/python3.10/site-packages/keras/engine/training_v1.py:854\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_call_args(\u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    853\u001b[0m func \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_training_loop(x)\n\u001b[0;32m--> 854\u001b[0m \u001b[39mreturn\u001b[39;00m func\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    855\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    856\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    857\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    858\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m    859\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    860\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    861\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    862\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[1;32m    863\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m    864\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m    865\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m    866\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    867\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m    868\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m    869\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m    870\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m    871\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m    872\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m    873\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m    874\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/anagoup/lib/python3.10/site-packages/keras/engine/training_generator_v1.py:647\u001b[0m, in \u001b[0;36mGeneratorOrSequenceTrainingLoop.fit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    643\u001b[0m model\u001b[39m.\u001b[39m_validate_or_infer_batch_size(batch_size, steps_per_epoch, x)\n\u001b[1;32m    644\u001b[0m training_utils_v1\u001b[39m.\u001b[39mcheck_generator_arguments(\n\u001b[1;32m    645\u001b[0m     y, sample_weight, validation_split\u001b[39m=\u001b[39mvalidation_split\n\u001b[1;32m    646\u001b[0m )\n\u001b[0;32m--> 647\u001b[0m \u001b[39mreturn\u001b[39;00m fit_generator(\n\u001b[1;32m    648\u001b[0m     model,\n\u001b[1;32m    649\u001b[0m     x,\n\u001b[1;32m    650\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[1;32m    651\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    652\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    653\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    654\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m    655\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m    656\u001b[0m     validation_freq\u001b[39m=\u001b[39;49mvalidation_freq,\n\u001b[1;32m    657\u001b[0m     class_weight\u001b[39m=\u001b[39;49mclass_weight,\n\u001b[1;32m    658\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m    659\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m    660\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m    661\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[1;32m    662\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49minitial_epoch,\n\u001b[1;32m    663\u001b[0m     steps_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msteps_per_epoch\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    664\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/anagoup/lib/python3.10/site-packages/keras/engine/training_generator_v1.py:282\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m callbacks\u001b[39m.\u001b[39m_call_batch_hook(mode, \u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m, step, batch_logs)\n\u001b[1;32m    281\u001b[0m is_deferred \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m model\u001b[39m.\u001b[39m_is_compiled\n\u001b[0;32m--> 282\u001b[0m batch_outs \u001b[39m=\u001b[39m batch_function(\u001b[39m*\u001b[39;49mbatch_data)\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(batch_outs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    284\u001b[0m     batch_outs \u001b[39m=\u001b[39m [batch_outs]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/anagoup/lib/python3.10/site-packages/keras/engine/training_v1.py:1179\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_sample_weight_modes(sample_weights\u001b[39m=\u001b[39msample_weights)\n\u001b[1;32m   1178\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_train_function()\n\u001b[0;32m-> 1179\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(ins)\n\u001b[1;32m   1181\u001b[0m \u001b[39mif\u001b[39;00m reset_metrics:\n\u001b[1;32m   1182\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset_metrics()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/anagoup/lib/python3.10/site-packages/keras/backend.py:4581\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4571\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   4572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callable_fn \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   4573\u001b[0m     \u001b[39mor\u001b[39;00m feed_arrays \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_feed_arrays\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4577\u001b[0m     \u001b[39mor\u001b[39;00m session \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\n\u001b[1;32m   4578\u001b[0m ):\n\u001b[1;32m   4579\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_callable(feed_arrays, feed_symbols, symbol_vals, session)\n\u001b[0;32m-> 4581\u001b[0m fetched \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_callable_fn(\u001b[39m*\u001b[39;49marray_vals, run_metadata\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_metadata)\n\u001b[1;32m   4582\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fetches) :])\n\u001b[1;32m   4583\u001b[0m output_structure \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mpack_sequence_as(\n\u001b[1;32m   4584\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs_structure,\n\u001b[1;32m   4585\u001b[0m     fetched[: \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs)],\n\u001b[1;32m   4586\u001b[0m     expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   4587\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/envs/anagoup/lib/python3.10/site-packages/tensorflow/python/client/session.py:1481\u001b[0m, in \u001b[0;36mBaseSession._Callable.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1480\u001b[0m   run_metadata_ptr \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_NewBuffer() \u001b[39mif\u001b[39;00m run_metadata \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1481\u001b[0m   ret \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39;49mTF_SessionRunCallable(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49m_session,\n\u001b[1;32m   1482\u001b[0m                                          \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle, args,\n\u001b[1;32m   1483\u001b[0m                                          run_metadata_ptr)\n\u001b[1;32m   1484\u001b[0m   \u001b[39mif\u001b[39;00m run_metadata:\n\u001b[1;32m   1485\u001b[0m     proto_data \u001b[39m=\u001b[39m tf_session\u001b[39m.\u001b[39mTF_GetBuffer(run_metadata_ptr)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: indices[18,18] = 4824 is not in [0, 4824)\n\t [[{{node word_embedding_3/embedding_lookup}}]]"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import modelli.trainer\n",
    "importlib.reload(modelli.trainer)\n",
    "from modelli.trainer import Trainer\n",
    "\n",
    "\n",
    "\n",
    "trainer = Trainer(lstm.model, preprocessor=lstm.p)\n",
    "trainer.train(X_train, Y_train, X_val, Y_val, epochs=1, batch_size=32,verbose=1,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import batch_get_value\n",
    "import pickle\n",
    "\n",
    "lstm.save(\"param\",\"weights.h5\",\"preprocessor\")\n",
    "symbolic_weights = getattr(lstm.model.optimizer, 'weights')\n",
    "weight_values = batch_get_value(symbolic_weights)\n",
    "with open('optimizer.pkl', 'wb') as f:\n",
    "    pickle.dump(weight_values, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelli.wrapper import Sequence\n",
    "\n",
    "lstm=Sequence (word_embedding_dim=100, embeddings=model_2.wv)\n",
    "lstm.fit(X_train, Y_train, X_val, Y_val, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelli.models import save_model\n",
    "\n",
    "save_model(lstm.model, \"weights.h5\",\"param\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.fit(X_train, Y_train, X_val, Y_val,epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anagoup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7613704cca6be61a35926d07e845db46a5adaf3e0bd32c31c32b93fe29930a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
