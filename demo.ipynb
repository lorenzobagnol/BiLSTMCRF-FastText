{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2048)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sentence=list()\n",
    "Y_sentence=list()\n",
    "count=0\n",
    "base_path=\"dataset\"\n",
    "X_train=list()\n",
    "Y_train=list()\n",
    "X_val=list()\n",
    "Y_val=list()\n",
    "X_test=list()\n",
    "Y_test=list()\n",
    "with open(base_path+\"/S1-test.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        if(line!='\\n'):\n",
    "            X_sentence.append(line.split(\" \")[0])\n",
    "            Y_sentence.append(line.split(\" \")[1][:-1])\n",
    "        else:\n",
    "            count+=1\n",
    "            if(count==2):\n",
    "                X_test.append(X_sentence)      \n",
    "                Y_test.append(Y_sentence)        \n",
    "                X_sentence=list()\n",
    "                Y_sentence=list()\n",
    "                count=0\n",
    "with open(base_path+\"/S2-train.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        if(line!='\\n'):\n",
    "            X_sentence.append(line.split(\" \")[0])\n",
    "            Y_sentence.append(line.split(\" \")[1][:-1])\n",
    "        else:\n",
    "            count+=1\n",
    "            if(count==2):\n",
    "                X_train.append(X_sentence)      \n",
    "                Y_train.append(Y_sentence)        \n",
    "                X_sentence=list()\n",
    "                Y_sentence=list()\n",
    "                count=0\n",
    "with open(base_path+\"/S3-val.txt\", encoding=\"utf8\") as file:\n",
    "    for line in file:\n",
    "        if(line!='\\n'):\n",
    "            X_sentence.append(line.split(\" \")[0])\n",
    "            Y_sentence.append(line.split(\" \")[1][:-1])\n",
    "        else:\n",
    "            count+=1\n",
    "            if(count==2):\n",
    "                X_val.append(X_sentence)      \n",
    "                Y_val.append(Y_sentence)        \n",
    "                X_sentence=list()\n",
    "                Y_sentence=list()\n",
    "                count=0\n",
    "# sentences it is a list of sentences. Every sentence is a list of tuple\n",
    "tokenized_sentences=X_train+X_test+X_val\n",
    "tokenized_labels=Y_train+Y_test+Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=0\n",
    "for sent in Y_train:\n",
    "    for el in sent:\n",
    "        if len(el)>2 and el[2:]=='BIOP':\n",
    "            print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "model_2=FastText(sentences=tokenized_sentences, vector_size=100, window=10, min_count=5, sg=1, negative=10, alpha=0.01, sample=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3047698, 6991040)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.train(tokenized_sentences, total_examples=len(tokenized_sentences), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelli.wrapper import Sequence\n",
    "import modelli.wrapper\n",
    "import importlib\n",
    "importlib.reload(modelli.wrapper)\n",
    "\n",
    "lstm=Sequence(embeddings=model_2.wv, initial_vocab=model_2.wv.key_to_index)\n",
    "lstm.fit_vocab(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_embedding KerasTensor(type_spec=TensorSpec(shape=(None, 17, 100), dtype=tf.float32, name=None), name='word_embedding/embedding_lookup/Identity_1:0', description=\"created by layer 'word_embedding'\")\n",
      "char_embedding KerasTensor(type_spec=TensorSpec(shape=(None, 17, 34, 25), dtype=tf.float32, name=None), name='char_embedding/embedding_lookup/Identity_1:0', description=\"created by layer 'char_embedding'\")\n",
      "char_blstm KerasTensor(type_spec=TensorSpec(shape=(None, 17, 50), dtype=tf.float32, name=None), name='time_distributed_7/Reshape_2:0', description=\"created by layer 'time_distributed_7'\")\n",
      "concatenation KerasTensor(type_spec=TensorSpec(shape=(None, 17, 150), dtype=tf.float32, name=None), name='concatenate_7/concat:0', description=\"created by layer 'concatenate_7'\")\n",
      "dropout KerasTensor(type_spec=TensorSpec(shape=(None, 17, 150), dtype=tf.float32, name=None), name='dropout_7/Identity:0', description=\"created by layer 'dropout_7'\")\n",
      "bilstm KerasTensor(type_spec=TensorSpec(shape=(None, 17, 200), dtype=tf.float32, name=None), name='bidirectional_15/concat:0', description=\"created by layer 'bidirectional_15'\")\n",
      "dense KerasTensor(type_spec=TensorSpec(shape=(None, 17, 100), dtype=tf.float32, name=None), name='dense_7/Tanh:0', description=\"created by layer 'dense_7'\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 17, 49) dtype=float32 (created by layer 'crf_7')>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "lstm.model.call((tf.keras.Input(shape=[17]),tf.keras.Input(shape=[17,34])),training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelli.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(lstm.model, preprocessor=lstm.p)\n",
    "trainer.train(X_train, Y_train, X_val, Y_val, epochs=1, batch_size=32, verbose=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import batch_get_value\n",
    "import pickle\n",
    "\n",
    "lstm.save(model_json=\"model_json\", model_file=\"model\", preprocessor_file=\"preprocessor\")\n",
    "# symbolic_weights = lstm.model.optimizer.variables()\n",
    "# weight_values = batch_get_value(symbolic_weights)\n",
    "# with open('optimizer.pkl', 'wb') as f:\n",
    " #    pickle.dump(symbolic_weights, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_json=lstm.model.to_json()\n",
    "with open('model_json', 'w') as f:\n",
    "    f.write(json.dumps(model_json))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelli.wrapper import Sequence\n",
    "\n",
    "lstm=Sequence.load(model_json=\"model_json\", model_folder=\"model\", preprocessor_file=\"preprocessor\")\n",
    "# lstm.model.optimizer.set_weights()\n",
    "# with open('optimizer.pkl', 'rb') as f:\n",
    "  #   weight_values = pickle.load(f)\n",
    "# lstm.model.optimizer.set_weights(weight_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Bi' object has no attribute '_num_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodelli\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m CRF\n\u001b[0;32m----> 2\u001b[0m lstm\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mCRF(lstm\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49m_num_labels)\u001b[39m.\u001b[39mloss_function, optimizer\u001b[39m=\u001b[39mlstm\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39moptimizer)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Bi' object has no attribute '_num_labels'"
     ]
    }
   ],
   "source": [
    "from modelli.layers import CRF\n",
    "lstm.model.compile(loss=CRF(lstm.model._num_labels).loss_function, optimizer=lstm.model.optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...bilstm\n",
      "......backward_layer\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......forward_layer\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......layer\n",
      ".........cell\n",
      "............vars\n",
      ".........vars\n",
      "......vars\n",
      "...char_bilstm\n",
      "......layer\n",
      ".........backward_layer\n",
      "............cell\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "..................2\n",
      "............vars\n",
      ".........forward_layer\n",
      "............cell\n",
      "...............vars\n",
      "..................0\n",
      "..................1\n",
      "..................2\n",
      "............vars\n",
      ".........layer\n",
      "............cell\n",
      "...............vars\n",
      "............vars\n",
      ".........vars\n",
      "......vars\n",
      "...char_embeddings\n",
      "......vars\n",
      ".........0\n",
      "...concat\n",
      "......vars\n",
      "...dense\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      "...dropout\n",
      "......vars\n",
      "...last_layer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      "...layers\n",
      "......embedding\n",
      ".........vars\n",
      "............0\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-21 12:01:02      6163908\n",
      "metadata.json                                  2023-03-21 12:01:02           64\n",
      "config.json                                    2023-03-21 12:01:02          456\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pickle.dump(lstm, open('wrapper.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "variables.h5                                   2023-03-21 12:01:02      6163908\n",
      "metadata.json                                  2023-03-21 12:01:02           64\n",
      "config.json                                    2023-03-21 12:01:02          456\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unable to revive model from config. When overriding the `get_config()`, make sure that the returned config contains all items used as arguments in the constructor to <class 'modelli.models.Bi'>, which is the default behavior. You can override this default behavior by defining a `from_config` method to specify how to create an instance of Bi from the config. \n\nError encountered during deserialization:\nBi.__init__() missing 2 required positional arguments: 'num_labels' and 'word_vocab_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/anagoup/lib/python3.10/site-packages/keras/engine/training.py:3130\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3129\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3130\u001b[0m     model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig)\n\u001b[1;32m   3131\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mTypeError\u001b[0m: Bi.__init__() missing 2 required positional arguments: 'num_labels' and 'word_vocab_size'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pickled_model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(\u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mwrapper.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/miniconda3/envs/anagoup/lib/python3.10/site-packages/keras/saving/pickle_utils.py:48\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[0;34m(serialized_model)\u001b[0m\n\u001b[1;32m     46\u001b[0m     model \u001b[39m=\u001b[39m saving_lib\u001b[39m.\u001b[39mload_model(filepath)\n\u001b[1;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m     49\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/anagoup/lib/python3.10/site-packages/keras/saving/pickle_utils.py:46\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[0;34m(serialized_model)\u001b[0m\n\u001b[1;32m     40\u001b[0m         f\u001b[39m.\u001b[39mwrite(serialized_model)\n\u001b[1;32m     41\u001b[0m     \u001b[39m# When loading, direct import will work for most custom objects\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[39m# though it will require get_config() to be implemented.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[39m# Some custom objects (e.g. an activation in a Dense layer,\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[39m# serialized as a string by Dense.get_config()) will require\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[39m# a custom_object_scope.\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     model \u001b[39m=\u001b[39m saving_lib\u001b[39m.\u001b[39;49mload_model(filepath)\n\u001b[1;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     48\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/miniconda3/envs/anagoup/lib/python3.10/site-packages/keras/saving/experimental/saving_lib.py:196\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects)\u001b[0m\n\u001b[1;32m    194\u001b[0m     h5_file\u001b[39m.\u001b[39mclose()\n\u001b[1;32m    195\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 196\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    197\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/anagoup/lib/python3.10/site-packages/keras/saving/experimental/saving_lib.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects)\u001b[0m\n\u001b[1;32m    181\u001b[0m config_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(config_json)\n\u001b[1;32m    182\u001b[0m \u001b[39m# Construct the model from the configuration file in the archive.\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m model \u001b[39m=\u001b[39m deserialize_keras_object(config_dict, custom_objects)\n\u001b[1;32m    184\u001b[0m h5_file \u001b[39m=\u001b[39m h5py\u001b[39m.\u001b[39mFile(tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mjoin(temp_path, _VARS_FNAME), \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    185\u001b[0m _print_h5_file(h5_file, action\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/anagoup/lib/python3.10/site-packages/keras/saving/experimental/serialization_lib.py:318\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[39m# Instantiate the class from its config inside a custom object scope\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[39m# so that we can catch any custom objects that the config refers to.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwith\u001b[39;00m object_registration\u001b[39m.\u001b[39mcustom_object_scope(custom_objects):\n\u001b[0;32m--> 318\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_config(inner_config)\n",
      "File \u001b[0;32m~/miniconda3/envs/anagoup/lib/python3.10/site-packages/keras/engine/training.py:3132\u001b[0m, in \u001b[0;36mModel.from_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   3130\u001b[0m         model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n\u001b[1;32m   3131\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 3132\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m   3133\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to revive model from config. When overriding \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3134\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mthe `get_config()`, make sure that the returned \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3135\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mconfig contains all items used as arguments in the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3136\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconstructor to \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, which is the default behavior. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3137\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou can override this default behavior by defining a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3138\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`from_config` method to specify how to create an \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3139\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstance of \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m from the config. \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3140\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError encountered during deserialization:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3141\u001b[0m         )\n\u001b[1;32m   3143\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(saving_lib\u001b[39m.\u001b[39m_SAVING_V3_ENABLED, \u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m   3144\u001b[0m     \u001b[39mif\u001b[39;00m build_input_shape:\n",
      "\u001b[0;31mTypeError\u001b[0m: Unable to revive model from config. When overriding the `get_config()`, make sure that the returned config contains all items used as arguments in the constructor to <class 'modelli.models.Bi'>, which is the default behavior. You can override this default behavior by defining a `from_config` method to specify how to create an instance of Bi from the config. \n\nError encountered during deserialization:\nBi.__init__() missing 2 required positional arguments: 'num_labels' and 'word_vocab_size'"
     ]
    }
   ],
   "source": [
    "pickled_model = pickle.load(open('wrapper.pkl', 'rb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anagoup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7613704cca6be61a35926d07e845db46a5adaf3e0bd32c31c32b93fe29930a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
